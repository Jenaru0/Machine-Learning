{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fcce78",
   "metadata": {},
   "source": [
    "# 🎓 Exploración Interactiva - Proyecto ML\n",
    "\n",
    "## 📊 Predicción de Rendimiento Académico Estudiantil\n",
    "\n",
    "### 👨‍🎓 Equipo Grupo 4\n",
    "- **Candela Vargas Aitor Baruc**\n",
    "- **Godoy Bautista Denilson Miguel**\n",
    "- **Molina Lazaro Eduardo Jeampier**\n",
    "- **Napanga Ruiz Jhonatan Jesus**\n",
    "- **Quispe Romani Angela Isabel**\n",
    "\n",
    "### 📚 Información del Proyecto\n",
    "- **Asignatura:** Machine Learning\n",
    "- **Docente:** M.SC. Magaly Roxana Aranguena Yllanes\n",
    "- **Año:** 2025\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook permite explorar interactivamente los datos del proyecto y experimentar con diferentes técnicas de Machine Learning para predecir el rendimiento académico de estudiantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bcdb4b",
   "metadata": {},
   "source": [
    "## 📦 1. Importar Librerías Necesarias\n",
    "\n",
    "Importamos todas las librerías necesarias para el análisis de datos y Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías estándar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Silenciar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar pandas para mostrar más columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Agregar el directorio src al path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "print(\"✅ Librerías importadas exitosamente\")\n",
    "print(\"📊 Configuración de visualización aplicada\")\n",
    "print(\"🔧 Entorno configurado para análisis interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd7e5e",
   "metadata": {},
   "source": [
    "## 📊 2. Cargar y Explorar Datos\n",
    "\n",
    "Cargamos el dataset original y realizamos una exploración inicial para entender la estructura y características de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09034cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset original\n",
    "try:\n",
    "    # Ruta al archivo de datos\n",
    "    data_path = Path.cwd().parent / \"datos\" / \"raw\" / \"StudentPerformanceFactors.csv\"\n",
    "    \n",
    "    # Cargar datos\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    print(\"✅ Dataset cargado exitosamente\")\n",
    "    print(f\"📊 Dimensiones: {df.shape}\")\n",
    "    print(f\"📋 Columnas: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Mostrar información básica\n",
    "    print(\"\\n🔍 Información del Dataset:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Mostrar primeras filas\n",
    "    print(\"\\n📋 Primeras 5 filas:\")\n",
    "    display(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: No se encontró el archivo de datos\")\n",
    "    print(\"💡 Asegúrese de que el archivo esté en la ruta correcta\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error cargando datos: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis estadístico básico\n",
    "print(\"📈 ESTADÍSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Estadísticas de variables numéricas\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"\\n🔢 Variables Numéricas:\")\n",
    "display(df[numeric_columns].describe())\n",
    "\n",
    "# Estadísticas de variables categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\n📊 Variables Categóricas ({len(categorical_columns)} columnas):\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts().head())\n",
    "\n",
    "# Análisis de valores nulos\n",
    "print(f\"\\n⚠️ VALORES NULOS:\")\n",
    "print(\"=\" * 30)\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() > 0:\n",
    "    print(missing_data[missing_data > 0])\n",
    "else:\n",
    "    print(\"✅ No hay valores nulos en el dataset\")\n",
    "\n",
    "# Análisis de duplicados\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "print(f\"\\n📋 Filas duplicadas: {duplicated_rows}\")\n",
    "if duplicated_rows > 0:\n",
    "    print(\"⚠️ Se encontraron filas duplicadas\")\n",
    "else:\n",
    "    print(\"✅ No hay filas duplicadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e744c",
   "metadata": {},
   "source": [
    "## 📊 3. Visualizaciones Exploratorias\n",
    "\n",
    "Creamos diferentes visualizaciones para entender mejor la distribución y relaciones entre las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49537c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la variable objetivo (Exam_Score)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Histograma de Exam_Score\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df['Exam_Score'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('📊 Distribución de Exam_Score')\n",
    "plt.xlabel('Puntaje del Examen')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot de Exam_Score\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df['Exam_Score'])\n",
    "plt.title('📦 Box Plot de Exam_Score')\n",
    "plt.ylabel('Puntaje del Examen')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Estadísticas de Exam_Score\n",
    "plt.subplot(1, 3, 3)\n",
    "stats = df['Exam_Score'].describe()\n",
    "plt.text(0.1, 0.9, f\"Media: {stats['mean']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.8, f\"Mediana: {stats['50%']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.7, f\"Desv. Std: {stats['std']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.6, f\"Mínimo: {stats['min']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.5, f\"Máximo: {stats['max']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.4, f\"Rango: {stats['max'] - stats['min']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.title('📈 Estadísticas de Exam_Score')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"📊 Análisis de Exam_Score:\")\n",
    "print(f\"   🎯 Media: {df['Exam_Score'].mean():.2f}\")\n",
    "print(f\"   📏 Rango: {df['Exam_Score'].min():.1f} - {df['Exam_Score'].max():.1f}\")\n",
    "print(f\"   📐 Desviación estándar: {df['Exam_Score'].std():.2f}\")\n",
    "print(f\"   📊 Coeficiente de variación: {(df['Exam_Score'].std() / df['Exam_Score'].mean() * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de correlaciones\n",
    "print(\"🔍 ANÁLISIS DE CORRELACIONES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Seleccionar solo variables numéricas\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calcular matriz de correlación\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Visualizar matriz de correlación\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Correlación'})\n",
    "plt.title('🔥 Matriz de Correlación - Variables Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones con Exam_Score\n",
    "print(\"\\n🎯 Correlaciones con Exam_Score:\")\n",
    "print(\"-\" * 40)\n",
    "exam_correlations = correlation_matrix['Exam_Score'].sort_values(ascending=False)\n",
    "for var, corr in exam_correlations.items():\n",
    "    if var != 'Exam_Score':\n",
    "        emoji = \"🟢\" if abs(corr) > 0.5 else \"🟡\" if abs(corr) > 0.3 else \"🔴\"\n",
    "        print(f\"{emoji} {var}: {corr:.3f}\")\n",
    "\n",
    "# Identificar correlaciones fuertes\n",
    "strong_correlations = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            strong_correlations.append((\n",
    "                correlation_matrix.columns[i], \n",
    "                correlation_matrix.columns[j], \n",
    "                corr_val\n",
    "            ))\n",
    "\n",
    "if strong_correlations:\n",
    "    print(f\"\\n⚠️ Correlaciones fuertes encontradas (|r| > 0.7):\")\n",
    "    for var1, var2, corr in strong_correlations:\n",
    "        print(f\"   {var1} ↔ {var2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(f\"\\n✅ No hay correlaciones excesivamente fuertes entre variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b42ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de variables categóricas vs Exam_Score\n",
    "print(\"👥 ANÁLISIS DE VARIABLES CATEGÓRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Seleccionar variables categóricas principales\n",
    "categorical_vars = ['Gender', 'Parental_Involvement', 'Access_to_Resources', \n",
    "                   'Motivation_Level', 'School_Type', 'Peer_Influence']\n",
    "\n",
    "# Verificar qué variables existen en el dataset\n",
    "available_cats = [var for var in categorical_vars if var in df.columns]\n",
    "\n",
    "if available_cats:\n",
    "    # Crear subplots para variables categóricas\n",
    "    n_vars = len(available_cats)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_vars + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    for i, var in enumerate(available_cats):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        # Calcular estadísticas por grupo\n",
    "        grouped_stats = df.groupby(var)['Exam_Score'].agg(['mean', 'count']).round(2)\n",
    "        \n",
    "        # Crear box plot\n",
    "        df.boxplot(column='Exam_Score', by=var, ax=plt.gca())\n",
    "        plt.title(f'📊 {var} vs Exam_Score')\n",
    "        plt.suptitle('')  # Eliminar título automático\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('Exam_Score')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Agregar estadísticas como texto\n",
    "        stats_text = \"\\\\n\".join([f\"{idx}: μ={row['mean']:.1f} (n={row['count']})\" \n",
    "                                for idx, row in grouped_stats.iterrows()])\n",
    "        plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, \n",
    "                fontsize=8, verticalalignment='top', \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar estadísticas detalladas\n",
    "    print(\"\\\\n📊 Estadísticas por grupos:\")\n",
    "    for var in available_cats:\n",
    "        print(f\"\\\\n{var}:\")\n",
    "        stats = df.groupby(var)['Exam_Score'].agg(['count', 'mean', 'std']).round(2)\n",
    "        print(stats)\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ No se encontraron variables categóricas disponibles para análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546a65d",
   "metadata": {},
   "source": [
    "## 🤖 4. Experimentación con Modelos\n",
    "\n",
    "Probamos diferentes modelos de Machine Learning de forma interactiva para comparar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8fcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación básica de datos para modelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🔧 PREPARACIÓN DE DATOS PARA MODELADO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear una copia del dataset para experimentación\n",
    "df_model = df.copy()\n",
    "\n",
    "# Separar variables numéricas y categóricas\n",
    "numeric_cols = df_model.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remover Exam_Score de las features numéricas si está presente\n",
    "if 'Exam_Score' in numeric_cols:\n",
    "    numeric_cols.remove('Exam_Score')\n",
    "\n",
    "print(f\"📊 Variables numéricas ({len(numeric_cols)}): {numeric_cols}\")\n",
    "print(f\"👥 Variables categóricas ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Codificar variables categóricas (simple label encoding para experimentación)\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col + '_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Crear feature matrix X\n",
    "feature_cols = numeric_cols + [col + '_encoded' for col in categorical_cols]\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['Exam_Score']\n",
    "\n",
    "print(f\"\\\\n✅ Dataset preparado:\")\n",
    "print(f\"   📊 Features: {X.shape[1]}\")\n",
    "print(f\"   📋 Muestras: {X.shape[0]}\")\n",
    "print(f\"   🎯 Variable objetivo: Exam_Score\")\n",
    "\n",
    "# Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\\\n📂 División train/test:\")\n",
    "print(f\"   🚂 Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"   🧪 Test: {X_test.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c970e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y comparación de modelos\n",
    "print(\"🚀 ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Escalar datos para modelos que lo requieren\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir modelos a probar\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (α=1.0)': Ridge(alpha=1.0),\n",
    "    'Ridge (α=10.0)': Ridge(alpha=10.0),\n",
    "    'Lasso (α=1.0)': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Entrenar modelos y recopilar resultados\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\\\n🔹 Entrenando {name}...\")\n",
    "    \n",
    "    # Decidir si usar datos escalados o no\n",
    "    if 'Ridge' in name or 'Lasso' in name:\n",
    "        X_train_use = X_train_scaled\n",
    "        X_test_use = X_test_scaled\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train_use, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_test_use)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✅ R² = {r2:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': list(results.keys()),\n",
    "    'R²': [results[name]['r2'] for name in results.keys()],\n",
    "    'RMSE': [results[name]['rmse'] for name in results.keys()],\n",
    "    'MAE': [results[name]['mae'] for name in results.keys()],\n",
    "    'MSE': [results[name]['mse'] for name in results.keys()]\n",
    "}).round(4)\n",
    "\n",
    "# Ordenar por R²\n",
    "results_df = results_df.sort_values('R²', ascending=False)\n",
    "\n",
    "print(f\"\\\\n🏆 RESULTADOS DE MODELOS:\")\n",
    "print(\"=\" * 50)\n",
    "display(results_df)\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_name = results_df.iloc[0]['Modelo']\n",
    "best_r2 = results_df.iloc[0]['R²']\n",
    "print(f\"\\\\n🥇 Mejor modelo: {best_model_name}\")\n",
    "print(f\"📈 R² Score: {best_r2:.4f}\")\n",
    "\n",
    "# Interpretación del rendimiento\n",
    "if best_r2 >= 0.8:\n",
    "    performance = \"Excelente 🌟\"\n",
    "elif best_r2 >= 0.6:\n",
    "    performance = \"Bueno 👍\"\n",
    "elif best_r2 >= 0.4:\n",
    "    performance = \"Moderado 🤔\"\n",
    "else:\n",
    "    performance = \"Pobre 👎\"\n",
    "\n",
    "print(f\"📊 Rendimiento: {performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de resultados de modelos\n",
    "print(\"📊 VISUALIZACIÓN DE RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear visualizaciones comparativas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Comparación de métricas R²\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.bar(range(len(results_df)), results_df['R²'], \n",
    "               color=['gold', 'silver', '#CD7F32', 'lightblue', 'lightgreen'])\n",
    "ax1.set_title('🏆 Comparación R² Score')\n",
    "ax1.set_xlabel('Modelos')\n",
    "ax1.set_ylabel('R² Score')\n",
    "ax1.set_xticks(range(len(results_df)))\n",
    "ax1.set_xticklabels(results_df['Modelo'], rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Comparación RMSE\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(range(len(results_df)), results_df['RMSE'], \n",
    "        color=['coral', 'orange', 'yellow', 'lightblue', 'lightgreen'])\n",
    "ax2.set_title('📉 Comparación RMSE')\n",
    "ax2.set_xlabel('Modelos')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_xticks(range(len(results_df)))\n",
    "ax2.set_xticklabels(results_df['Modelo'], rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Predicciones vs Valores Reales (mejor modelo)\n",
    "ax3 = axes[1, 0]\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "ax3.scatter(y_test, best_predictions, alpha=0.6, color='blue')\n",
    "ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax3.set_title(f'🎯 {best_model_name}\\\\nPredicciones vs Valores Reales')\n",
    "ax3.set_xlabel('Valores Reales')\n",
    "ax3.set_ylabel('Predicciones')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar estadísticas al gráfico\n",
    "ax3.text(0.05, 0.95, f'R² = {best_r2:.3f}', transform=ax3.transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 4. Distribución de errores (mejor modelo)\n",
    "ax4 = axes[1, 1]\n",
    "errors = y_test - best_predictions\n",
    "ax4.hist(errors, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "ax4.set_title(f'📊 Distribución de Errores\\\\n{best_model_name}')\n",
    "ax4.set_xlabel('Error (Real - Predicción)')\n",
    "ax4.set_ylabel('Frecuencia')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar línea vertical en cero\n",
    "ax4.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Agregar estadísticas de errores\n",
    "error_mean = errors.mean()\n",
    "error_std = errors.std()\n",
    "ax4.text(0.05, 0.95, f'μ = {error_mean:.2f}\\\\nσ = {error_std:.2f}', \n",
    "         transform=ax4.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis de residuos del mejor modelo\n",
    "print(f\"\\\\n🔍 ANÁLISIS DE RESIDUOS - {best_model_name}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"📊 Error promedio: {errors.mean():.4f}\")\n",
    "print(f\"📊 Desviación estándar de errores: {errors.std():.4f}\")\n",
    "print(f\"📊 Error máximo: {errors.max():.4f}\")\n",
    "print(f\"📊 Error mínimo: {errors.min():.4f}\")\n",
    "\n",
    "# Verificar normalidad de residuos (prueba simple)\n",
    "from scipy import stats\n",
    "_, p_value = stats.normaltest(errors)\n",
    "if p_value > 0.05:\n",
    "    print(f\"✅ Los residuos parecen seguir una distribución normal (p-value: {p_value:.4f})\")\n",
    "else:\n",
    "    print(f\"⚠️ Los residuos no siguen una distribución normal (p-value: {p_value:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
