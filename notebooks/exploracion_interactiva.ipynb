{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fcce78",
   "metadata": {},
   "source": [
    "# üéì Exploraci√≥n Interactiva - Proyecto ML\n",
    "\n",
    "## üìä Predicci√≥n de Rendimiento Acad√©mico Estudiantil\n",
    "\n",
    "### üë®‚Äçüéì Equipo Grupo 4\n",
    "- **Candela Vargas Aitor Baruc**\n",
    "- **Godoy Bautista Denilson Miguel**\n",
    "- **Molina Lazaro Eduardo Jeampier**\n",
    "- **Napanga Ruiz Jhonatan Jesus**\n",
    "- **Quispe Romani Angela Isabel**\n",
    "\n",
    "### üìö Informaci√≥n del Proyecto\n",
    "- **Asignatura:** Machine Learning\n",
    "- **Docente:** M.SC. Magaly Roxana Aranguena Yllanes\n",
    "- **A√±o:** 2025\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook permite explorar interactivamente los datos del proyecto y experimentar con diferentes t√©cnicas de Machine Learning para predecir el rendimiento acad√©mico de estudiantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bcdb4b",
   "metadata": {},
   "source": [
    "## üì¶ 1. Importar Librer√≠as Necesarias\n",
    "\n",
    "Importamos todas las librer√≠as necesarias para el an√°lisis de datos y Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as est√°ndar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Silenciar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar pandas para mostrar m√°s columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Agregar el directorio src al path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas exitosamente\")\n",
    "print(\"üìä Configuraci√≥n de visualizaci√≥n aplicada\")\n",
    "print(\"üîß Entorno configurado para an√°lisis interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd7e5e",
   "metadata": {},
   "source": [
    "## üìä 2. Cargar y Explorar Datos\n",
    "\n",
    "Cargamos el dataset original y realizamos una exploraci√≥n inicial para entender la estructura y caracter√≠sticas de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09034cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset original\n",
    "try:\n",
    "    # Ruta al archivo de datos\n",
    "    data_path = Path.cwd().parent / \"datos\" / \"raw\" / \"StudentPerformanceFactors.csv\"\n",
    "    \n",
    "    # Cargar datos\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    print(\"‚úÖ Dataset cargado exitosamente\")\n",
    "    print(f\"üìä Dimensiones: {df.shape}\")\n",
    "    print(f\"üìã Columnas: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Mostrar informaci√≥n b√°sica\n",
    "    print(\"\\nüîç Informaci√≥n del Dataset:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Mostrar primeras filas\n",
    "    print(\"\\nüìã Primeras 5 filas:\")\n",
    "    display(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: No se encontr√≥ el archivo de datos\")\n",
    "    print(\"üí° Aseg√∫rese de que el archivo est√© en la ruta correcta\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando datos: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis estad√≠stico b√°sico\n",
    "print(\"üìà ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Estad√≠sticas de variables num√©ricas\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"\\nüî¢ Variables Num√©ricas:\")\n",
    "display(df[numeric_columns].describe())\n",
    "\n",
    "# Estad√≠sticas de variables categ√≥ricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nüìä Variables Categ√≥ricas ({len(categorical_columns)} columnas):\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts().head())\n",
    "\n",
    "# An√°lisis de valores nulos\n",
    "print(f\"\\n‚ö†Ô∏è VALORES NULOS:\")\n",
    "print(\"=\" * 30)\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() > 0:\n",
    "    print(missing_data[missing_data > 0])\n",
    "else:\n",
    "    print(\"‚úÖ No hay valores nulos en el dataset\")\n",
    "\n",
    "# An√°lisis de duplicados\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "print(f\"\\nüìã Filas duplicadas: {duplicated_rows}\")\n",
    "if duplicated_rows > 0:\n",
    "    print(\"‚ö†Ô∏è Se encontraron filas duplicadas\")\n",
    "else:\n",
    "    print(\"‚úÖ No hay filas duplicadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e744c",
   "metadata": {},
   "source": [
    "## üìä 3. Visualizaciones Exploratorias\n",
    "\n",
    "Creamos diferentes visualizaciones para entender mejor la distribuci√≥n y relaciones entre las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49537c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de la variable objetivo (Exam_Score)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Histograma de Exam_Score\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df['Exam_Score'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('üìä Distribuci√≥n de Exam_Score')\n",
    "plt.xlabel('Puntaje del Examen')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot de Exam_Score\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df['Exam_Score'])\n",
    "plt.title('üì¶ Box Plot de Exam_Score')\n",
    "plt.ylabel('Puntaje del Examen')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Estad√≠sticas de Exam_Score\n",
    "plt.subplot(1, 3, 3)\n",
    "stats = df['Exam_Score'].describe()\n",
    "plt.text(0.1, 0.9, f\"Media: {stats['mean']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.8, f\"Mediana: {stats['50%']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.7, f\"Desv. Std: {stats['std']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.6, f\"M√≠nimo: {stats['min']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.5, f\"M√°ximo: {stats['max']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.text(0.1, 0.4, f\"Rango: {stats['max'] - stats['min']:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "plt.title('üìà Estad√≠sticas de Exam_Score')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä An√°lisis de Exam_Score:\")\n",
    "print(f\"   üéØ Media: {df['Exam_Score'].mean():.2f}\")\n",
    "print(f\"   üìè Rango: {df['Exam_Score'].min():.1f} - {df['Exam_Score'].max():.1f}\")\n",
    "print(f\"   üìê Desviaci√≥n est√°ndar: {df['Exam_Score'].std():.2f}\")\n",
    "print(f\"   üìä Coeficiente de variaci√≥n: {(df['Exam_Score'].std() / df['Exam_Score'].mean() * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de correlaciones\n",
    "print(\"üîç AN√ÅLISIS DE CORRELACIONES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Seleccionar solo variables num√©ricas\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calcular matriz de correlaci√≥n\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Visualizar matriz de correlaci√≥n\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Correlaci√≥n'})\n",
    "plt.title('üî• Matriz de Correlaci√≥n - Variables Num√©ricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones con Exam_Score\n",
    "print(\"\\nüéØ Correlaciones con Exam_Score:\")\n",
    "print(\"-\" * 40)\n",
    "exam_correlations = correlation_matrix['Exam_Score'].sort_values(ascending=False)\n",
    "for var, corr in exam_correlations.items():\n",
    "    if var != 'Exam_Score':\n",
    "        emoji = \"üü¢\" if abs(corr) > 0.5 else \"üü°\" if abs(corr) > 0.3 else \"üî¥\"\n",
    "        print(f\"{emoji} {var}: {corr:.3f}\")\n",
    "\n",
    "# Identificar correlaciones fuertes\n",
    "strong_correlations = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            strong_correlations.append((\n",
    "                correlation_matrix.columns[i], \n",
    "                correlation_matrix.columns[j], \n",
    "                corr_val\n",
    "            ))\n",
    "\n",
    "if strong_correlations:\n",
    "    print(f\"\\n‚ö†Ô∏è Correlaciones fuertes encontradas (|r| > 0.7):\")\n",
    "    for var1, var2, corr in strong_correlations:\n",
    "        print(f\"   {var1} ‚Üî {var2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No hay correlaciones excesivamente fuertes entre variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b42ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de variables categ√≥ricas vs Exam_Score\n",
    "print(\"üë• AN√ÅLISIS DE VARIABLES CATEG√ìRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Seleccionar variables categ√≥ricas principales\n",
    "categorical_vars = ['Gender', 'Parental_Involvement', 'Access_to_Resources', \n",
    "                   'Motivation_Level', 'School_Type', 'Peer_Influence']\n",
    "\n",
    "# Verificar qu√© variables existen en el dataset\n",
    "available_cats = [var for var in categorical_vars if var in df.columns]\n",
    "\n",
    "if available_cats:\n",
    "    # Crear subplots para variables categ√≥ricas\n",
    "    n_vars = len(available_cats)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_vars + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    for i, var in enumerate(available_cats):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        # Calcular estad√≠sticas por grupo\n",
    "        grouped_stats = df.groupby(var)['Exam_Score'].agg(['mean', 'count']).round(2)\n",
    "        \n",
    "        # Crear box plot\n",
    "        df.boxplot(column='Exam_Score', by=var, ax=plt.gca())\n",
    "        plt.title(f'üìä {var} vs Exam_Score')\n",
    "        plt.suptitle('')  # Eliminar t√≠tulo autom√°tico\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('Exam_Score')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Agregar estad√≠sticas como texto\n",
    "        stats_text = \"\\\\n\".join([f\"{idx}: Œº={row['mean']:.1f} (n={row['count']})\" \n",
    "                                for idx, row in grouped_stats.iterrows()])\n",
    "        plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, \n",
    "                fontsize=8, verticalalignment='top', \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar estad√≠sticas detalladas\n",
    "    print(\"\\\\nüìä Estad√≠sticas por grupos:\")\n",
    "    for var in available_cats:\n",
    "        print(f\"\\\\n{var}:\")\n",
    "        stats = df.groupby(var)['Exam_Score'].agg(['count', 'mean', 'std']).round(2)\n",
    "        print(stats)\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron variables categ√≥ricas disponibles para an√°lisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546a65d",
   "metadata": {},
   "source": [
    "## ü§ñ 4. Experimentaci√≥n con Modelos\n",
    "\n",
    "Probamos diferentes modelos de Machine Learning de forma interactiva para comparar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8fcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaci√≥n b√°sica de datos para modelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üîß PREPARACI√ìN DE DATOS PARA MODELADO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear una copia del dataset para experimentaci√≥n\n",
    "df_model = df.copy()\n",
    "\n",
    "# Separar variables num√©ricas y categ√≥ricas\n",
    "numeric_cols = df_model.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remover Exam_Score de las features num√©ricas si est√° presente\n",
    "if 'Exam_Score' in numeric_cols:\n",
    "    numeric_cols.remove('Exam_Score')\n",
    "\n",
    "print(f\"üìä Variables num√©ricas ({len(numeric_cols)}): {numeric_cols}\")\n",
    "print(f\"üë• Variables categ√≥ricas ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Codificar variables categ√≥ricas (simple label encoding para experimentaci√≥n)\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col + '_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Crear feature matrix X\n",
    "feature_cols = numeric_cols + [col + '_encoded' for col in categorical_cols]\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['Exam_Score']\n",
    "\n",
    "print(f\"\\\\n‚úÖ Dataset preparado:\")\n",
    "print(f\"   üìä Features: {X.shape[1]}\")\n",
    "print(f\"   üìã Muestras: {X.shape[0]}\")\n",
    "print(f\"   üéØ Variable objetivo: Exam_Score\")\n",
    "\n",
    "# Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\\\nüìÇ Divisi√≥n train/test:\")\n",
    "print(f\"   üöÇ Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"   üß™ Test: {X_test.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c970e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y comparaci√≥n de modelos\n",
    "print(\"üöÄ ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Escalar datos para modelos que lo requieren\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir modelos a probar\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (Œ±=1.0)': Ridge(alpha=1.0),\n",
    "    'Ridge (Œ±=10.0)': Ridge(alpha=10.0),\n",
    "    'Lasso (Œ±=1.0)': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Entrenar modelos y recopilar resultados\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\\\nüîπ Entrenando {name}...\")\n",
    "    \n",
    "    # Decidir si usar datos escalados o no\n",
    "    if 'Ridge' in name or 'Lasso' in name:\n",
    "        X_train_use = X_train_scaled\n",
    "        X_test_use = X_test_scaled\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train_use, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_test_use)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ R¬≤ = {r2:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': list(results.keys()),\n",
    "    'R¬≤': [results[name]['r2'] for name in results.keys()],\n",
    "    'RMSE': [results[name]['rmse'] for name in results.keys()],\n",
    "    'MAE': [results[name]['mae'] for name in results.keys()],\n",
    "    'MSE': [results[name]['mse'] for name in results.keys()]\n",
    "}).round(4)\n",
    "\n",
    "# Ordenar por R¬≤\n",
    "results_df = results_df.sort_values('R¬≤', ascending=False)\n",
    "\n",
    "print(f\"\\\\nüèÜ RESULTADOS DE MODELOS:\")\n",
    "print(\"=\" * 50)\n",
    "display(results_df)\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_name = results_df.iloc[0]['Modelo']\n",
    "best_r2 = results_df.iloc[0]['R¬≤']\n",
    "print(f\"\\\\nü•á Mejor modelo: {best_model_name}\")\n",
    "print(f\"üìà R¬≤ Score: {best_r2:.4f}\")\n",
    "\n",
    "# Interpretaci√≥n del rendimiento\n",
    "if best_r2 >= 0.8:\n",
    "    performance = \"Excelente üåü\"\n",
    "elif best_r2 >= 0.6:\n",
    "    performance = \"Bueno üëç\"\n",
    "elif best_r2 >= 0.4:\n",
    "    performance = \"Moderado ü§î\"\n",
    "else:\n",
    "    performance = \"Pobre üëé\"\n",
    "\n",
    "print(f\"üìä Rendimiento: {performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de resultados de modelos\n",
    "print(\"üìä VISUALIZACI√ìN DE RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear visualizaciones comparativas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Comparaci√≥n de m√©tricas R¬≤\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.bar(range(len(results_df)), results_df['R¬≤'], \n",
    "               color=['gold', 'silver', '#CD7F32', 'lightblue', 'lightgreen'])\n",
    "ax1.set_title('üèÜ Comparaci√≥n R¬≤ Score')\n",
    "ax1.set_xlabel('Modelos')\n",
    "ax1.set_ylabel('R¬≤ Score')\n",
    "ax1.set_xticks(range(len(results_df)))\n",
    "ax1.set_xticklabels(results_df['Modelo'], rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Comparaci√≥n RMSE\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(range(len(results_df)), results_df['RMSE'], \n",
    "        color=['coral', 'orange', 'yellow', 'lightblue', 'lightgreen'])\n",
    "ax2.set_title('üìâ Comparaci√≥n RMSE')\n",
    "ax2.set_xlabel('Modelos')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_xticks(range(len(results_df)))\n",
    "ax2.set_xticklabels(results_df['Modelo'], rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Predicciones vs Valores Reales (mejor modelo)\n",
    "ax3 = axes[1, 0]\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "ax3.scatter(y_test, best_predictions, alpha=0.6, color='blue')\n",
    "ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax3.set_title(f'üéØ {best_model_name}\\\\nPredicciones vs Valores Reales')\n",
    "ax3.set_xlabel('Valores Reales')\n",
    "ax3.set_ylabel('Predicciones')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar estad√≠sticas al gr√°fico\n",
    "ax3.text(0.05, 0.95, f'R¬≤ = {best_r2:.3f}', transform=ax3.transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 4. Distribuci√≥n de errores (mejor modelo)\n",
    "ax4 = axes[1, 1]\n",
    "errors = y_test - best_predictions\n",
    "ax4.hist(errors, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "ax4.set_title(f'üìä Distribuci√≥n de Errores\\\\n{best_model_name}')\n",
    "ax4.set_xlabel('Error (Real - Predicci√≥n)')\n",
    "ax4.set_ylabel('Frecuencia')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar l√≠nea vertical en cero\n",
    "ax4.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Agregar estad√≠sticas de errores\n",
    "error_mean = errors.mean()\n",
    "error_std = errors.std()\n",
    "ax4.text(0.05, 0.95, f'Œº = {error_mean:.2f}\\\\nœÉ = {error_std:.2f}', \n",
    "         transform=ax4.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de residuos del mejor modelo\n",
    "print(f\"\\\\nüîç AN√ÅLISIS DE RESIDUOS - {best_model_name}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"üìä Error promedio: {errors.mean():.4f}\")\n",
    "print(f\"üìä Desviaci√≥n est√°ndar de errores: {errors.std():.4f}\")\n",
    "print(f\"üìä Error m√°ximo: {errors.max():.4f}\")\n",
    "print(f\"üìä Error m√≠nimo: {errors.min():.4f}\")\n",
    "\n",
    "# Verificar normalidad de residuos (prueba simple)\n",
    "from scipy import stats\n",
    "_, p_value = stats.normaltest(errors)\n",
    "if p_value > 0.05:\n",
    "    print(f\"‚úÖ Los residuos parecen seguir una distribuci√≥n normal (p-value: {p_value:.4f})\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Los residuos no siguen una distribuci√≥n normal (p-value: {p_value:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
