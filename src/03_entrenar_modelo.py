"""
Entrenamiento y Optimizaci√≥n de Modelos
=======================================

M√≥dulo que implementa exactamente el c√≥digo de las GU√çAS 3 y 4 para el entrenamiento
y optimizaci√≥n de modelos de Machine Learning.

Incluye:
- Regresi√≥n lineal simple (Gu√≠a 3)
- Optimizaci√≥n de hiperpar√°metros con Ridge y Lasso (Gu√≠a 4)
- Validaci√≥n cruzada y selecci√≥n del mejor modelo
- Evaluaci√≥n de m√©tricas y serializaci√≥n

Autor: Equipo Grupo 4
Fecha: 2025
"""

import pandas as pd
import numpy as np
import logging
from pathlib import Path
from typing import Tuple, Dict, Any
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Importaciones de sklearn
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Importar configuraci√≥n y utilidades
import importlib
config = importlib.import_module('src.00_config')
utils = importlib.import_module('src.00_utils')

# Extraer funciones y constantes necesarias
ARCHIVO_TRAIN = config.ARCHIVO_TRAIN
ARCHIVO_TEST = config.ARCHIVO_TEST
ARCHIVO_PREDICCIONES = config.ARCHIVO_PREDICCIONES
MODELO_RIDGE_PATH = config.MODELO_RIDGE_PATH
ALPHAS_RIDGE = config.ALPHAS_RIDGE
ALPHAS_LASSO = config.ALPHAS_LASSO
MAX_ITER_LASSO = config.MAX_ITER_LASSO
CV_FOLDS = config.CV_FOLDS
MEJOR_ALPHA_RIDGE = config.MEJOR_ALPHA_RIDGE
MENSAJES = config.MENSAJES
FIGSIZE_LARGE = config.FIGSIZE_LARGE

cargar_dataframe = utils.cargar_dataframe
guardar_dataframe = utils.guardar_dataframe
guardar_pickle = utils.guardar_pickle
imprimir_separador = utils.imprimir_separador
limpiar_memoria = utils.limpiar_memoria

def entrenar_regresion_lineal_simple() -> Dict[str, Any]:
    """
    Entrena regresi√≥n lineal simple siguiendo exactamente el c√≥digo de la Gu√≠a 3.
    
    Returns:
        Dict[str, Any]: Diccionario con modelo y predicciones
    """
    imprimir_separador("REGRESI√ìN LINEAL SIMPLE - GU√çA 3")
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 1
    # 1. Importar librer√≠as (importadas al inicio del archivo)
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 3 (cargar datos)
    # 3. Leer los CSV en DataFrames
    df_train = cargar_dataframe(ARCHIVO_TRAIN)
    df_test = cargar_dataframe(ARCHIVO_TEST)
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 4
    # 4. Confirmar nombre de la columna objetivo
    print("Columnas en train:", df_train.columns.tolist())
    print("Columnas en test: ", df_test.columns.tolist())
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 5
    # 5. Separar features y target
    target_col = 'Exam_Score'   # ‚Üê debe estar en df_train y df_test
    X_train = df_train.drop(target_col, axis=1)
    y_train = df_train[target_col]
    
    X_test = df_test.drop(target_col, axis=1)
    y_test = df_test[target_col]
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 6
    # 6. Entrenar el modelo de regresi√≥n lineal
    modelo = LinearRegression()
    modelo.fit(X_train, y_train)
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 7
    # 7. Generar predicciones sobre el test
    y_pred = modelo.predict(X_test)
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 7.1
    # 7.1 Mostrar las primeras 5 predicciones
    print("Primeras predicciones:")
    print(pd.DataFrame(y_pred, columns=['Predicted_Exam_Score']).head())
    
    # C√≥digo exacto de la Gu√≠a 3 - Paso 7.2
    # 7.2 Estad√≠sticos descriptivos de las predicciones
    print("\nEstad√≠sticos descriptivos de Predicted_Exam_Score:")
    print(pd.Series(y_pred, name='Predicted_Exam_Score').describe().round(3))
    
    print("‚úÖ Regresi√≥n lineal simple completada")
    
    return {
        'modelo': modelo,
        'predicciones': y_pred,
        'X_test': X_test,
        'y_test': y_test,
        'nombre': 'Linear Regression'
    }

def entrenar_modelos_optimizados() -> Dict[str, Any]:
    """
    Entrena modelos con optimizaci√≥n de hiperpar√°metros siguiendo exactamente el c√≥digo de la Gu√≠a 4.
    
    Returns:
        Dict[str, Any]: Diccionario con resultados de todos los modelos
    """
    imprimir_separador("OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - GU√çA 4")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 1
    # 1. Importar librer√≠as (importadas al inicio del archivo)
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 3
    # 3. Leer los CSV en DataFrames
    df_train = cargar_dataframe(ARCHIVO_TRAIN)
    df_test = cargar_dataframe(ARCHIVO_TEST)
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 4
    # 4. Confirmar nombre de la columna objetivo
    print("Columnas en train:", df_train.columns.tolist())
    print("Columnas en test: ", df_test.columns.tolist())
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 5
    # 5. Separar features y target
    target_col = 'Exam_Score'
    X_train = df_train.drop(target_col, axis=1)
    y_train = df_train[target_col]
    
    # Ahora el test S√ç tiene Exam_Score
    X_test = df_test.drop(target_col, axis=1)
    y_test = df_test[target_col]
    
    print(f"üìä Tama√±o del conjunto de entrenamiento: {X_train.shape}")
    print(f"üìä Tama√±o del conjunto de prueba: {X_test.shape}")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 6
    # 6. Preparar datos para modelos regularizados
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 7
    # 7. Definir modelos y sus hiperpar√°metros
    print("\n" + "="*50)
    print("üîß ENTRENANDO Y OPTIMIZANDO MODELOS")
    print("="*50)
    
    modelos = {
        'Linear Regression': {
            'modelo': LinearRegression(),
            'params': {},
            'scaled': False
        },
        'Ridge': {
            'modelo': Ridge(random_state=42),
            'params': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},
            'scaled': True
        },
        'Lasso': {
            'modelo': Lasso(random_state=42),
            'params': {
                'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],
                'max_iter': [1000, 2000, 3000]
            },
            'scaled': True
        }
    }
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 8
    # 8. Entrenar y optimizar cada modelo
    resultados = {}
    
    for nombre, config in modelos.items():
        print(f"\nüîπ Entrenando {nombre}...")
        
        # Seleccionar datos (escalados o no)
        X_train_use = X_train_scaled if config['scaled'] else X_train
        X_test_use = X_test_scaled if config['scaled'] else X_test
        
        if config['params']:  # Si tiene hiperpar√°metros que optimizar
            # Grid Search con validaci√≥n cruzada
            grid_search = GridSearchCV(
                config['modelo'],
                config['params'],
                cv=5,
                scoring='neg_mean_squared_error',
                n_jobs=-1
            )
            grid_search.fit(X_train_use, y_train)
            mejor_modelo = grid_search.best_estimator_
            print(f"   üìä Mejores hiperpar√°metros: {grid_search.best_params_}")
            print(f"   üìà Mejor score CV: {-grid_search.best_score_:.3f}")
        else:  # Regresi√≥n lineal simple
            mejor_modelo = config['modelo']
            mejor_modelo.fit(X_train_use, y_train)
        
        # Predicciones
        y_pred = mejor_modelo.predict(X_test_use)
        
        # M√©tricas
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # Guardar resultados
        resultados[nombre] = {
            'modelo': mejor_modelo,
            'predicciones': y_pred,
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'X_test_use': X_test_use,
            'scaler': scaler if config['scaled'] else None
        }
        
        print(f"   ‚úÖ R¬≤ = {r2:.3f}, RMSE = {rmse:.3f}")
    
    print("‚úÖ Optimizaci√≥n de modelos completada")
    return resultados, y_test

def comparar_modelos(resultados: Dict[str, Any]) -> pd.DataFrame:
    """
    Compara modelos siguiendo exactamente el c√≥digo de la Gu√≠a 4.
    
    Args:
        resultados (Dict[str, Any]): Resultados de todos los modelos
        
    Returns:
        pd.DataFrame: DataFrame con comparaci√≥n de modelos
    """
    imprimir_separador("COMPARACI√ìN DE MODELOS")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 9
    # 9. COMPARACI√ìN DE MODELOS
    print("\n" + "="*60)
    print("üìä COMPARACI√ìN DE MODELOS")
    print("="*60)
    
    # Crear tabla comparativa
    df_comparacion = pd.DataFrame({
        'Modelo': list(resultados.keys()),
        'R¬≤': [res['r2'] for res in resultados.values()],
        'RMSE': [res['rmse'] for res in resultados.values()],
        'MAE': [res['mae'] for res in resultados.values()],
        'MSE': [res['mse'] for res in resultados.values()]
    })
    
    # Ordenar por R¬≤ (descendente)
    df_comparacion = df_comparacion.sort_values('R¬≤', ascending=False)
    print(df_comparacion.round(6))
    
    # Identificar el mejor modelo
    mejor_modelo_nombre = df_comparacion.iloc[0]['Modelo']
    print(f"\nüèÜ MEJOR MODELO: {mejor_modelo_nombre}")
    print(f"   üìà R¬≤ = {df_comparacion.iloc[0]['R¬≤']:.4f}")
    print(f"   üìâ RMSE = {df_comparacion.iloc[0]['RMSE']:.4f}")
    
    return df_comparacion

def generar_visualizaciones(resultados: Dict[str, Any], y_test: pd.Series, 
                          df_comparacion: pd.DataFrame) -> None:
    """
    Genera visualizaciones siguiendo exactamente el c√≥digo de la Gu√≠a 4.
    
    Args:
        resultados (Dict[str, Any]): Resultados de todos los modelos
        y_test (pd.Series): Valores reales de test
        df_comparacion (pd.DataFrame): DataFrame con comparaci√≥n de modelos
    """
    imprimir_separador("GENERANDO VISUALIZACIONES")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 10
    # 10. Visualizaci√≥n comparativa
    plt.figure(figsize=(18, 12))
    
    # Gr√°fico 1: Comparaci√≥n de m√©tricas
    plt.subplot(2, 3, 1)
    x_pos = np.arange(len(df_comparacion))
    plt.bar(x_pos, df_comparacion['R¬≤'], alpha=0.7, color=['gold', 'silver', 'brown'])
    plt.xlabel('Modelos')
    plt.ylabel('R¬≤')
    plt.title('Comparaci√≥n R¬≤')
    plt.xticks(x_pos, df_comparacion['Modelo'], rotation=45)
    plt.grid(True, alpha=0.3)
    
    plt.subplot(2, 3, 2)
    plt.bar(x_pos, df_comparacion['RMSE'], alpha=0.7, color=['gold', 'silver', 'brown'])
    plt.xlabel('Modelos')
    plt.ylabel('RMSE')
    plt.title('Comparaci√≥n RMSE')
    plt.xticks(x_pos, df_comparacion['Modelo'], rotation=45)
    plt.grid(True, alpha=0.3)
    
    # Gr√°ficos 3-5: Predicciones vs Reales para cada modelo
    for i, (nombre, res) in enumerate(resultados.items()):
        plt.subplot(2, 3, i+3)
        plt.scatter(y_test, res['predicciones'], alpha=0.6)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.xlabel('Valores Reales')
        plt.ylabel('Predicciones')
        plt.title(f'{nombre}\nR¬≤ = {res["r2"]:.3f}')
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("‚úÖ Visualizaciones generadas")

def analizar_coeficientes(resultados: Dict[str, Any], X_train: pd.DataFrame) -> None:
    """
    Analiza coeficientes siguiendo exactamente el c√≥digo de la Gu√≠a 4.
    
    Args:
        resultados (Dict[str, Any]): Resultados de todos los modelos
        X_train (pd.DataFrame): DataFrame de entrenamiento
    """
    imprimir_separador("AN√ÅLISIS DE COEFICIENTES")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 11
    # 11. An√°lisis de coeficientes (para Ridge y Lasso)
    print("\n" + "="*50)
    print("üîç AN√ÅLISIS DE COEFICIENTES")
    print("="*50)
    
    feature_names = X_train.columns.tolist()
    
    for nombre in ['Ridge', 'Lasso']:
        if nombre in resultados:
            modelo = resultados[nombre]['modelo']
            coeficientes = modelo.coef_
            
            # Crear DataFrame con coeficientes
            df_coef = pd.DataFrame({
                'Feature': feature_names,
                'Coeficiente': coeficientes,
                'Abs_Coeficiente': np.abs(coeficientes)
            }).sort_values('Abs_Coeficiente', ascending=False)
            
            print(f"\n{nombre} - Top 5 caracter√≠sticas m√°s importantes:")
            print(df_coef.head().round(6))
            
            # Contar coeficientes cero en Lasso
            if nombre == 'Lasso':
                coef_cero = np.sum(np.abs(coeficientes) < 1e-10)
                print(f"   üìä Caracter√≠sticas eliminadas por Lasso: {coef_cero}/{len(coeficientes)}")
    
    print("‚úÖ An√°lisis de coeficientes completado")

def evaluar_mejor_modelo(resultados: Dict[str, Any], y_test: pd.Series, 
                        mejor_modelo_nombre: str) -> None:
    """
    Eval√∫a el mejor modelo siguiendo exactamente el c√≥digo de la Gu√≠a 4.
    
    Args:
        resultados (Dict[str, Any]): Resultados de todos los modelos
        y_test (pd.Series): Valores reales de test
        mejor_modelo_nombre (str): Nombre del mejor modelo
    """
    imprimir_separador(f"EVALUACI√ìN DETALLADA: {mejor_modelo_nombre}")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 13
    # 13. EVALUACI√ìN DETALLADA DEL MEJOR MODELO
    mejor_resultado = resultados[mejor_modelo_nombre]
    y_pred_final = mejor_resultado['predicciones']
    
    print("\n" + "="*50)
    print(f"üìä EVALUACI√ìN DETALLADA: {mejor_modelo_nombre}")
    print("="*50)
    
    # Usar las predicciones del mejor modelo
    mse = mean_squared_error(y_test, y_pred_final)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred_final)
    r2 = r2_score(y_test, y_pred_final)
    
    print(f"MSE (Error Cuadr√°tico Medio): {mse:.3f}")
    print(f"RMSE (Ra√≠z del ECM): {rmse:.3f}")
    print(f"MAE (Error Absoluto Medio): {mae:.3f}")
    print(f"R¬≤ (Coeficiente de Determinaci√≥n): {r2:.3f}")
    
    # Interpretaci√≥n del R¬≤
    if r2 >= 0.8:
        interpretacion = "Excelente"
    elif r2 >= 0.6:
        interpretacion = "Bueno"
    elif r2 >= 0.4:
        interpretacion = "Moderado"
    else:
        interpretacion = "Pobre"
    
    print(f"üìã Interpretaci√≥n del modelo: {interpretacion} (R¬≤ = {r2:.3f})")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 14
    # 14. Comparaci√≥n de predicciones vs valores reales (mejor modelo)
    print("\n" + "="*50)
    print("üîç COMPARACI√ìN: PREDICCIONES vs VALORES REALES")
    print("="*50)
    
    # Crear DataFrame con comparaci√≥n
    comparacion = pd.DataFrame({
        'Valor_Real': y_test,
        'Prediccion': np.round(y_pred_final, 6),
        'Error_Absoluto': np.abs(y_test - y_pred_final)
    })
    
    print("Primeras 10 comparaciones:")
    print(comparacion.head(10))
    
    print(f"\nError promedio: {comparacion['Error_Absoluto'].mean():.3f}")
    print(f"Error m√°ximo: {comparacion['Error_Absoluto'].max():.3f}")
    print(f"Error m√≠nimo: {comparacion['Error_Absoluto'].min():.3f}")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 16
    # 16. Estad√≠sticos descriptivos
    print("\n" + "="*50)
    print("üìà ESTAD√çSTICOS DESCRIPTIVOS")
    print("="*50)
    
    print("Valores Reales:")
    print(y_test.describe().round(6))
    
    print(f"\nPredicciones ({mejor_modelo_nombre}):")
    print(pd.Series(y_pred_final, name='Exam_Score').describe().round(6))
    
    print("‚úÖ Evaluaci√≥n detallada completada")

def guardar_mejor_modelo(resultados: Dict[str, Any], mejor_modelo_nombre: str) -> None:
    """
    Guarda el mejor modelo siguiendo las especificaciones del proyecto.
    
    Args:
        resultados (Dict[str, Any]): Resultados de todos los modelos
        mejor_modelo_nombre (str): Nombre del mejor modelo
    """
    imprimir_separador("GUARDANDO MEJOR MODELO")
    
    mejor_resultado = resultados[mejor_modelo_nombre]
    mejor_modelo = mejor_resultado['modelo']
    
    # Guardar modelo
    guardar_pickle(mejor_modelo, MODELO_RIDGE_PATH)
    
    # Si hay scaler, guardarlo tambi√©n
    if mejor_resultado.get('scaler'):
        scaler_path = MODELO_RIDGE_PATH.parent / "scaler.pkl"
        guardar_pickle(mejor_resultado['scaler'], scaler_path)
    
    print(f"‚úÖ Mejor modelo guardado: {mejor_modelo_nombre}")

def generar_predicciones_finales(resultados: Dict[str, Any], mejor_modelo_nombre: str) -> None:
    """
    Genera predicciones finales siguiendo exactamente el c√≥digo de la Gu√≠a 4.
    
    Args:
        resultados (Dict[str, Any]): Resultados de todos los modelos
        mejor_modelo_nombre (str): Nombre del mejor modelo
    """
    imprimir_separador("GENERANDO PREDICCIONES FINALES")
    
    # C√≥digo exacto de la Gu√≠a 4 - Paso 17
    # 17. Guardar predicciones del mejor modelo
    mejor_resultado = resultados[mejor_modelo_nombre]
    y_pred_final = mejor_resultado['predicciones']
    
    # Cargar datos de test para obtener las features
    df_test = cargar_dataframe(ARCHIVO_TEST)
    X_test = df_test.drop('Exam_Score', axis=1)
    
    df_pred = X_test.copy()
    df_pred['Exam_Score'] = np.round(y_pred_final, 6)
    
    guardar_dataframe(df_pred, ARCHIVO_PREDICCIONES)
    
    print(f"‚úÖ Predicciones finales guardadas usando {mejor_modelo_nombre}")

def ejecutar_entrenamiento_completo() -> Dict[str, Any]:
    """
    Ejecuta el entrenamiento completo de modelos.
    
    Returns:
        Dict[str, Any]: Resultados del entrenamiento
    """
    try:
        print(MENSAJES['inicio_entrenamiento'])
        
        # Entrenar regresi√≥n lineal simple (Gu√≠a 3)
        resultado_lineal = entrenar_regresion_lineal_simple()
        
        # Entrenar modelos optimizados (Gu√≠a 4)
        resultados, y_test = entrenar_modelos_optimizados()
        
        # Comparar modelos
        df_comparacion = comparar_modelos(resultados)
        
        # Generar visualizaciones
        generar_visualizaciones(resultados, y_test, df_comparacion)
        
        # Analizar coeficientes
        df_train = cargar_dataframe(ARCHIVO_TRAIN)
        X_train = df_train.drop('Exam_Score', axis=1)
        analizar_coeficientes(resultados, X_train)
        
        # Evaluar mejor modelo
        mejor_modelo_nombre = df_comparacion.iloc[0]['Modelo']
        evaluar_mejor_modelo(resultados, y_test, mejor_modelo_nombre)
        
        # Guardar mejor modelo
        guardar_mejor_modelo(resultados, mejor_modelo_nombre)
        
        # Generar predicciones finales
        generar_predicciones_finales(resultados, mejor_modelo_nombre)
        
        # Limpiar memoria
        limpiar_memoria()
        
        print(f"\n{MENSAJES['fin_entrenamiento']}")
        
        return {
            'resultados': resultados,
            'comparacion': df_comparacion,
            'mejor_modelo': mejor_modelo_nombre,
            'y_test': y_test
        }
        
    except Exception as e:
        logging.error(f"‚ùå Error en entrenamiento: {str(e)}")
        raise

def main():
    """Funci√≥n principal para ejecutar el entrenamiento."""
    resultados = ejecutar_entrenamiento_completo()
    return resultados

if __name__ == "__main__":
    # Importar m√©tricas necesarias (ya importadas al inicio)
    main()
